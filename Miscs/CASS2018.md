# CASS 2018

## Ryzen Processor Microarchitecture

* ![1562382571358](D:\OneDrive\Pictures\Typora\1562382571358.png)
* ![1562382589497](D:\OneDrive\Pictures\Typora\1562382589497.png)
* ![1562382619200](D:\OneDrive\Pictures\Typora\1562382619200.png)
* ![1562382628309](D:\OneDrive\Pictures\Typora\1562382628309.png)
* ![1562382663595](D:\OneDrive\Pictures\Typora\1562382663595.png)
* ![1562382678641](D:\OneDrive\Pictures\Typora\1562382678641.png)
* ![1562382701477](D:\OneDrive\Pictures\Typora\1562382701477.png)
* ![1562382711053](D:\OneDrive\Pictures\Typora\1562382711053.png)
* ![1562382732445](D:\OneDrive\Pictures\Typora\1562382732445.png)
* ![1562382823963](D:\OneDrive\Pictures\Typora\1562382823963.png)
* ![1562382852873](D:\OneDrive\Pictures\Typora\1562382852873.png)



## Understanding DRAM Architecture

* ![1562392171812](D:\OneDrive\Pictures\Typora\1562392171812.png)
* ![1562392200086](D:\OneDrive\Pictures\Typora\1562392200086.png)
* `![1562392932516](D:\OneDrive\Pictures\Typora\1562392932516.png)
* ![1562393363344](D:\OneDrive\Pictures\Typora\1562393363344.png)
* ![1562395787198](D:\OneDrive\Pictures\Typora\1562395787198.png)
* Memory controller
  * frontend
    * request/response buffers
    * memory mapping
    * aribiter
  * backend
    * command generator
* Bank-level parallelism
  * ![1562395921713](D:\OneDrive\Pictures\Typora\1562395921713.png)
  * improve performance with parallelism and row buffer hit
  * hurt performance due to bank-to-bank switch delay
* DRAM refresh
  * capacitors leak and lose charge -> need periodic restoration of charge
* Scheduling
  * ![1562396119540](D:\OneDrive\Pictures\Typora\1562396119540.png)
* Non-Volatile Memory (NVM)
* ![1562396152664](D:\OneDrive\Pictures\Typora\1562396152664.png)
* ![1562396162965](D:\OneDrive\Pictures\Typora\1562396162965.png)
* stacked DRAM
  * ![1562396181257](D:\OneDrive\Pictures\Typora\1562396181257.png)
  * ![1562396195939](D:\OneDrive\Pictures\Typora\1562396195939.png)
  * ![1562396277826](D:\OneDrive\Pictures\Typora\1562396277826.png)
  * ![1562396291675](D:\OneDrive\Pictures\Typora\1562396291675.png)
  * ![1562396299902](D:\OneDrive\Pictures\Typora\1562396299902.png)
  * ![1562396315487](D:\OneDrive\Pictures\Typora\1562396315487.png)
  * bi-modal cache
    * ![1562396332738](D:\OneDrive\Pictures\Typora\1562396332738.png)
    * ![1562396410272](D:\OneDrive\Pictures\Typora\1562396410272.png)
    * ![1562396420676](D:\OneDrive\Pictures\Typora\1562396420676.png)



## GPU Architecture

* CUDA programming
  * ![1562396894559](D:\OneDrive\Pictures\Typora\1562396894559.png)
  * cuda kernel $\ni$ array of light-weight threads
    * all threads run the same code (SPMD), but on same data
    * each thread has an ID that it uses to compute memory addresses and make control decisions
  * group threads into multiple blocks
    * threads within a block cooperate via shared memory and barrier synchronization
    * thread block scheduled on a single SM
    * consecutive k(=32) threads (within a block) form a wrap
    * instructions from a ready wrap is scheduled each cycle.
  * A kernel is executed as a grid of thread blocks
    * grid can be a 2-dim array of thread blocks
  * A thread block is a batch of threads that can cooperate with each other
    * synchronization
    * efficiently sharing data through a low latency shared memory
  * Each thread block can be a 1-D, 2-D, 3-D array of threads
  * ![1562399236875](D:\OneDrive\Pictures\Typora\1562399236875.png)
  * ![1562399435441](D:\OneDrive\Pictures\Typora\1562399435441.png)
* Processing flow
  * Copy input data from CPU memory to GPU memory (PCIe Bus)
  * Load GPU program and execute, caching data on chip for performance
  * Copy result from GPU memory to CPU memory
* Streaming Multiprocessor
  * ![1562399726639](D:\OneDrive\Pictures\Typora\1562399726639.png)
* CUDA Core
  * ![1562399883135](D:\OneDrive\Pictures\Typora\1562399883135.png)
* Memory hierarchy
  * thread
    * registers
    * local memory
  * block of threads
    * shared memory
  * global memory
    * accessible by all threads of any kernel
    * data lifetime: from allocation to deallocation by host code
    * latency: 400-800 cycles
    * bandwidth: 156GB/s
  * coalescing
* Scheduling
  * threadblocks
    * ![1562401525143](D:\OneDrive\Pictures\Typora\1562401525143.png)
    * ![1562401535252](D:\OneDrive\Pictures\Typora\1562401535252.png)
  * SM wrap
    * ![1562401640375](D:\OneDrive\Pictures\Typora\1562401640375.png)
    * ![1562401659547](D:\OneDrive\Pictures\Typora\1562401659547.png)
* ![1562401729853](D:\OneDrive\Pictures\Typora\1562401729853.png)
* branch divergence
  * ![1562401754030](D:\OneDrive\Pictures\Typora\1562401754030.png)
  * ![1562401761005](D:\OneDrive\Pictures\Typora\1562401761005.png)
* ![1562401773312](D:\OneDrive\Pictures\Typora\1562401773312.png)



## Parallel Architecture & Parallelization Principles

* parallel machine
  * 1+ processor
  * interacting
* shared memory
  * ![1562577807274](D:\OneDrive\Pictures\Typora\1562577807274.png)
  * UMA (uniform memory access)
    * centralized
  * NUMA (non-uniform memory access)
    * distributed
  * hybrid
* Interconnection
  * indirect: nodes are connected to interconnection medium, not directly to each other
    * shared bus / multiple bus / crossbar / MIN
  * direct: nodes are connected directly to each other
    * topology (linear/ring/star/mesh/torus/hybercube)
    * routing
  * ![1562578198152](D:\OneDrive\Pictures\Typora\1562578198152.png)
  * ![1562578204272](D:\OneDrive\Pictures\Typora\1562578204272.png)
* task: arbitrary piece of work in parallel computation
  * sequentially (concurrency only across tasks)
  * fine-grained vs coarse-grained
* process: abstract entity that performs the tasks
  * communicate & synchronize
* processor: physical engine on which process executes
* decomposition
  * task decomposition (computation partitioned)
    * task graphs, synchronization among tasks
  * data/domain decomposition
    * computation follows data: owner computes
    * data mining
* Creating a parallel program
  * Decomposition of computation into tasks
    * identity concurrency
    * break up computation into tasks to be divided among processes
      * dynamically tasks
      * no. of available tasks may vary with time
    * goal: expose available parallelism -> enough tasks to keep processor busy
  * Assignment of tasks to processes
    * specifies how to group tasks together for a process
      * balance workload
      * reduce communication
      * reduce management cost
    * structured approaches
    * usually independent of architecture or programming model
  * Orchestration of data access, communication, and synchronization
    * ![1562580955424](D:\OneDrive\Pictures\Typora\1562580955424.png)
  * Mapping processes to processors
  * ![1562580980489](D:\OneDrive\Pictures\Typora\1562580980489.png)
  * ![1562578746074](D:\OneDrive\Pictures\Typora\1562578746074.png)
* OpenMP
* MPI







## World of Predictors

* branch prediction
  * whether fetched instruction is a branch
  * branch direction
  * branch target address if taken
* Branch Target Buffer (BTB)
  * ![1562581381723](D:\OneDrive\Pictures\Typora\1562581381723.png)
* static
  * always not-taken
  * always taken
  * backward taken, forward not taken (BTFN)
  * profile-based
* dynamic
  * last time predictor (1-bit counter)
  * n-bit counter
  * two level global branch prediction
    * ![1562581414114](D:\OneDrive\Pictures\Typora\1562581414114.png)
    * GShare
    * Y & P Classification
  * Tournament
  * Neural & TAGE
    * ![1562581489530](D:\OneDrive\Pictures\Typora\1562581489530.png)
* Value prediction
  * ![1562581525859](D:\OneDrive\Pictures\Typora\1562581525859.png)
  * ![1562581531610](D:\OneDrive\Pictures\Typora\1562581531610.png)
* Non-blocking cache
  * ![1562581589124](D:\OneDrive\Pictures\Typora\1562581589124.png)
  * ![1562581594615](D:\OneDrive\Pictures\Typora\1562581594615.png)
  * ![1562581602493](D:\OneDrive\Pictures\Typora\1562581602493.png)
* Replacement policy
  * LRU
  * RRIP
    * ![1562581688065](D:\OneDrive\Pictures\Typora\1562581688065.png)
    * ![1562581695148](D:\OneDrive\Pictures\Typora\1562581695148.png)



## ISA and RISC-V

* Concepts
  * Data Storage
    * Storage Architecture
      * ![1562641708226](D:\OneDrive\Pictures\Typora\1562641708226.png)
      * ![1562641850013](D:\OneDrive\Pictures\Typora\1562641850013.png)
    * General Purpose Register Architecture
      * ![1562643081652](D:\OneDrive\Pictures\Typora\1562643081652.png)
  * Memory Addressing Modes
    * ![1562643923463](D:\OneDrive\Pictures\Typora\1562643923463.png)
    * ![1562643934051](D:\OneDrive\Pictures\Typora\1562643934051.png)
    * ![1562643942390](D:\OneDrive\Pictures\Typora\1562643942390.png)
  * Operations in the Instruction Set
    * ![1562643957717](D:\OneDrive\Pictures\Typora\1562643957717.png)
  * Instruction Formats
    * ![1562643977264](D:\OneDrive\Pictures\Typora\1562643977264.png)
    * ![1562643998231](D:\OneDrive\Pictures\Typora\1562643998231.png)
  * Encoding the Instruction Set
    * ![1562644014007](D:\OneDrive\Pictures\Typora\1562644014007.png)
    * ![1562644021480](D:\OneDrive\Pictures\Typora\1562644021480.png)
* RISC-V
  * simplicity favours regularity
  * smaller is faster
  * make the common case fast
  * good design demands good compromises
  * variable length encoding, base 32bit
  * ![1562658011256](D:\OneDrive\Pictures\Typora\1562658011256.png)
  * 